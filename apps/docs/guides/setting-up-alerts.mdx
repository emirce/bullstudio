---
title: "Setting Up Alerts"
description: "Step-by-step guide to configuring queue monitoring alerts"
---

Alerts notify you when your queues experience issues like high failure rates, growing backlogs, or slow processing. This guide walks through setting up effective alerts for your production queues.

<Info>
  Alerts require a **Pro** or **Enterprise** plan. [Upgrade your plan](/platform/billing) to enable alerts.
</Info>

## Prerequisites

Before setting up alerts, ensure you have:

- A bullstudio account with Pro or Enterprise plan
- At least one Redis connection configured
- Queues actively processing jobs (for meaningful thresholds)

## Step 1: Understand Your Baseline

Before creating alerts, understand your normal operating metrics:

<Steps>
  <Step title="Open the Dashboard">
    Navigate to your workspace and select your connection.
  </Step>
  <Step title="Review metrics for 24-48 hours">
    Look at:
    - Normal failure rate (typically < 1% for healthy queues)
    - Average processing time
    - Typical queue depth (waiting jobs)
    - Throughput patterns
  </Step>
  <Step title="Note your thresholds">
    Write down values that would indicate a problem:
    - Failure rate: 2-3x your normal rate
    - Processing time: 2-3x your normal average
    - Backlog: 10x your normal waiting count
  </Step>
</Steps>

<Tip>
  Spend time observing your metrics before setting thresholds. Alerts based on real data are more effective than guesses.
</Tip>

## Step 2: Create Your First Alert

Start with a **Failure Rate** alertâ€”the most universally useful type:

<Steps>
  <Step title="Navigate to Alerts">
    Go to your workspace and click **Alerts** in the sidebar.
  </Step>
  <Step title="Click Create Alert">
    Click the **Create Alert** button.
  </Step>
  <Step title="Configure the alert">
    Fill in the form:

    | Field | Value | Notes |
    |-------|-------|-------|
    | **Name** | High Failure Rate | Descriptive name |
    | **Connection** | Your production connection | Select from dropdown |
    | **Queue** | Your main queue | Or leave blank for all queues |
    | **Type** | Failure Rate | |
    | **Threshold** | 5% | Adjust based on your baseline |
    | **Time Window** | 15 minutes | Period to calculate rate |
    | **Resolve Threshold** | 2% | When to consider resolved |
    | **Recipients** | your-email@example.com | Add team members |
    | **Cooldown** | 15 minutes | Prevent spam |
  </Step>
  <Step title="Save">
    Click **Save** to create the alert.
  </Step>
</Steps>

## Step 3: Add Essential Alerts

For comprehensive monitoring, set up these additional alerts:

### Backlog Alert

Detects when jobs are piling up faster than workers can process:

```
Name: Queue Backlog High
Type: Backlog Exceeded
Threshold: 1000 jobs (adjust based on your scale)
Resolve Threshold: 500 jobs
```

<Warning>
  Set backlog thresholds based on your normal queue depth. A queue that typically has 10 waiting jobs is different from one with 1000.
</Warning>

### Processing Time Alert

Detects performance degradation:

```
Name: Slow Processing
Type: Processing Time (Avg)
Threshold: 5000ms (adjust based on your baseline)
Time Window: 15 minutes
Resolve Threshold: 2000ms
```

### Missing Workers Alert

Detects when all workers have stopped:

```
Name: No Active Workers
Type: Missing Workers
Grace Period: 5 minutes
```

<Tip>
  The Missing Workers alert is especially important for production. It catches scenarios where all workers have crashed.
</Tip>

## Step 4: Test Your Alerts

Verify alerts are configured correctly:

<Steps>
  <Step title="Open alert details">
    Click on the alert you want to test.
  </Step>
  <Step title="Click Test">
    Click the **Test** button.
  </Step>
  <Step title="Check your email">
    Verify you received the test notification.
  </Step>
</Steps>

## Alert Configuration Tips

### Choosing Thresholds

| Scenario | Suggested Approach |
|----------|-------------------|
| **High-volume queues** | Use percentage-based thresholds, shorter time windows |
| **Low-volume queues** | Use longer time windows to avoid noise |
| **Critical queues** | Set tighter thresholds, faster cooldowns |
| **Background jobs** | More relaxed thresholds, longer cooldowns |

### Time Window Guidelines

| Queue Volume | Recommended Window |
|--------------|-------------------|
| > 1000 jobs/hour | 5-10 minutes |
| 100-1000 jobs/hour | 15-30 minutes |
| < 100 jobs/hour | 30-60 minutes |

### Cooldown Strategy

- **Critical alerts**: 5-15 minutes
- **Standard alerts**: 15-30 minutes
- **Low-priority alerts**: 1-4 hours

## Common Alert Configurations

### E-commerce Order Processing

```yaml
Alert 1: Order Failures
- Type: Failure Rate
- Threshold: 2%
- Window: 10 minutes
- Cooldown: 5 minutes

Alert 2: Order Backlog
- Type: Backlog Exceeded
- Threshold: 500 orders
- Cooldown: 15 minutes

Alert 3: Slow Checkout
- Type: Processing Time (P95)
- Threshold: 10000ms
- Window: 10 minutes
```

### Email Notification System

```yaml
Alert 1: Email Failures
- Type: Failure Rate
- Threshold: 5%
- Window: 15 minutes

Alert 2: Email Backlog
- Type: Backlog Exceeded
- Threshold: 10000 emails

Alert 3: Missing Senders
- Type: Missing Workers
- Grace Period: 10 minutes
```

### Data Pipeline

```yaml
Alert 1: Pipeline Failures
- Type: Failure Rate
- Threshold: 1%
- Window: 30 minutes

Alert 2: Slow Processing
- Type: Processing Time (Avg)
- Threshold: 60000ms
- Window: 30 minutes
```

## Responding to Alerts

When you receive an alert:

<Steps>
  <Step title="Acknowledge">
    Note the alert and begin investigation.
  </Step>
  <Step title="Check the Dashboard">
    Open bullstudio and review metrics for the affected queue.
  </Step>
  <Step title="Investigate Jobs">
    Go to the Jobs page, filter by failed jobs, and examine error messages.
  </Step>
  <Step title="Take Action">
    - Retry jobs if it was a transient issue
    - Fix bugs and deploy
    - Scale workers if backlogged
    - Check external dependencies
  </Step>
  <Step title="Document">
    Record what happened and how it was resolved for future reference.
  </Step>
</Steps>

## Avoiding Alert Fatigue

- Start with fewer alerts and add more as needed
- Use resolve thresholds to prevent flapping
- Set appropriate cooldown periods
- Review and adjust thresholds monthly
- Disable alerts for non-critical queues during known maintenance

## Next Steps

<Columns cols={2}>
  <Card title="Alert Types" icon="bell" href="/features/alerts">
    Learn about all available alert types.
  </Card>
  <Card title="Monitoring Best Practices" icon="star" href="/guides/monitoring-best-practices">
    General monitoring strategies.
  </Card>
  <Card title="Dashboard" icon="chart-line" href="/features/dashboard">
    Understand your metrics baseline.
  </Card>
  <Card title="Troubleshooting" icon="wrench" href="/guides/troubleshooting">
    Common issues and solutions.
  </Card>
</Columns>
